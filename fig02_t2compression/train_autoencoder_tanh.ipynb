{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from python_utils import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers   = 2\n",
    "nonlinearity   = 'tanh'\n",
    "latent_nums    = [1,2,3,4]\n",
    "learning_rates = [1e-5,1e-5,1e-5,1e-5]\n",
    "all_epochs     = [100000,100000,100000,100000]\n",
    " \n",
    "test_skip_idx = 10   #grab every 10th entry of dictionary for testing\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the baseline dictionary\n",
    "dictionary = sio.loadmat('data/dictionary.mat')['dictionary']\n",
    "t2_range   = sio.loadmat('data/dict_params.mat')['dictionary_params'][0][0][3]\n",
    "    \n",
    "dictionary = np.real(dictionary)\n",
    "    \n",
    "t2_range_training = np.expand_dims(np.delete(t2_range,slice(None,None,test_skip_idx)),axis=0)\n",
    "t2_range_testing  = t2_range[:,::test_skip_idx]\n",
    "\n",
    "dictionary_training = np.delete(dictionary,slice(None,None,test_skip_idx),axis=1)\n",
    "dictionary_testing  = dictionary[:,::test_skip_idx]\n",
    "    \n",
    "[T,Ntraining] = dictionary_training.shape\n",
    "[_,Ntesting]  = dictionary_testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "#re-shaping dictionary, casting it to right type, and sending it to GPU\n",
    "dictionary_for_training = torch.tensor(np.transpose(dictionary_training,(1,0)),dtype = torch.float).to(device)\n",
    "\n",
    "all_models = []\n",
    "\n",
    "for latent_num,epochs,learning_rate in zip(latent_nums,all_epochs,learning_rates):\n",
    "    starting_time = time.time()\n",
    "\n",
    "    print('Latent Variables: %d || epochs: %d || learning rate: %.3f' % (latent_num,epochs,learning_rate))\n",
    "\n",
    "    model = models.autoencoder(T,latent_num,model_layers,nonlinearity)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(dictionary_for_training)\n",
    "        loss   = criterion(output,dictionary_for_training)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "\n",
    "        if(epoch % 1000 == 0):\n",
    "            print('  iteration %d/%d current loss: %.12f' % (epoch,epochs,running_loss))\n",
    "\n",
    "    print('  final loss: %.12f' % running_loss)\n",
    "    ending_time = time.time()\n",
    "    print('  elapsed time: %.2f min' % ((ending_time - starting_time)/60))\n",
    "\n",
    "    all_models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing training and testing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = lambda truth, comp: np.sqrt(np.sum((comp - truth)**2,keepdims=False,axis=0)) / np.sqrt(np.sum(truth**2,keepdims=False,axis=0))\n",
    "\n",
    "[u,s,v] = np.linalg.svd(dictionary,full_matrices=False)\n",
    "\n",
    "all_basis = []\n",
    "\n",
    "linear_errors_training   = []\n",
    "proposed_errors_training = []\n",
    "\n",
    "linear_errors_testing   = []\n",
    "proposed_errors_testing = []\n",
    "\n",
    "for latent_num, model in zip(latent_nums,all_models):\n",
    "    #determine basis\n",
    "    basis = u[:,0:latent_num]\n",
    "\n",
    "    #estimate dictionaries with svd and autoencoder\n",
    "    dictionary_estimate_linear_training   = basis @ np.conj(basis.T) @ dictionary_training\n",
    "    dictionary_estimate_proposed_training = model(dictionary_for_training).cpu().detach().numpy().transpose((1,0))\n",
    "\n",
    "    dictionary_estimate_linear_testing    = basis @ np.conj(basis.T) @ dictionary_testing\n",
    "    dictionary_for_testing                = \\\n",
    "        torch.tensor(np.transpose(dictionary_testing,(1,0)),dtype = torch.float).to(device)\n",
    "    dictionary_estimate_proposed_testing = \\\n",
    "        model(dictionary_for_testing).cpu().detach().numpy().transpose((1,0))\n",
    "\n",
    "    error_linear_training   = rmse(dictionary_training,dictionary_estimate_linear_training)\n",
    "    error_proposed_training = rmse(dictionary_training,dictionary_estimate_proposed_training)\n",
    "\n",
    "    error_linear_testing    = rmse(dictionary_testing,dictionary_estimate_linear_testing)\n",
    "    error_proposed_testing  = rmse(dictionary_testing,dictionary_estimate_proposed_testing)\n",
    "\n",
    "    linear_errors_training.append(error_linear_training)\n",
    "    proposed_errors_training.append(error_proposed_training)\n",
    "\n",
    "    linear_errors_testing.append(error_linear_testing)\n",
    "    proposed_errors_testing.append(error_proposed_testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting entry by entry training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 3\n",
    "for latent_num,error_linear,error_proposed in zip(latent_nums,linear_errors_training,proposed_errors_training):\n",
    "    print('average percent errors:')\n",
    "    print('  proposed: %.2f' % (np.mean(error_proposed)*100))\n",
    "    print('  linear:   %.2f' % (np.mean(error_linear)*100))\n",
    "    \n",
    "    plt.title('Latent Variables: %d' % latent_num,fontsize=24)\n",
    "    plt.plot(error_proposed,linewidth=lw)\n",
    "    plt.plot(error_linear,linewidth=lw)\n",
    "    plt.legend(['proposed','linear'],prop={'size':20})\n",
    "    plt.ylim([0,.4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting entry by entry testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 3\n",
    "for latent_num,error_linear,error_proposed in zip(latent_nums,linear_errors_testing,proposed_errors_testing):\n",
    "    print('average percent errors:')\n",
    "    print('  proposed: %.2f' % (np.mean(error_proposed)*100))\n",
    "    print('  linear:   %.2f' % (np.mean(error_linear)*100))\\\n",
    "    \n",
    "    plt.title('Latent Variables: %d' % latent_num,fontsize=24)\n",
    "    plt.plot(error_proposed,linewidth = lw)\n",
    "    plt.plot(error_linear,  linewidth = lw)\n",
    "    plt.legend(['proposed','linear'],prop={'size':20})\n",
    "    plt.ylim([0,.4])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
