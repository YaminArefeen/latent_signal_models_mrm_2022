{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bart \n",
    "\n",
    "from python_utils import models\n",
    "from python_utils import signalprocessing as sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_one_dim(x: torch.Tensor, shift: int, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to roll but for only one dim.\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        shift: Amount to roll.\n",
    "        dim: Which dimension to roll.\n",
    "    Returns:\n",
    "        Rolled version of x.\n",
    "    \"\"\"\n",
    "    shift = shift % x.size(dim)\n",
    "    if shift == 0:\n",
    "        return x\n",
    "\n",
    "    left = x.narrow(dim, 0, x.size(dim) - shift)\n",
    "    right = x.narrow(dim, x.size(dim) - shift, shift)\n",
    "\n",
    "    return torch.cat((right, left), dim=dim)\n",
    "\n",
    "def roll(\n",
    "    x: torch.Tensor,\n",
    "    shift: List[int],\n",
    "    dim: List[int],\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.roll but applies to PyTorch Tensors.\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        shift: Amount to roll.\n",
    "        dim: Which dimension to roll.\n",
    "    Returns:\n",
    "        Rolled version of x.\n",
    "    \"\"\"\n",
    "    if len(shift) != len(dim):\n",
    "        raise ValueError(\"len(shift) must match len(dim)\")\n",
    "\n",
    "    for (s, d) in zip(shift, dim):\n",
    "        x = roll_one_dim(x, s, d)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def fftshift(x: torch.Tensor, dim: Optional[List[int]] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.fft.fftshift but applies to PyTorch Tensors\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        dim: Which dimension to fftshift.\n",
    "    Returns:\n",
    "        fftshifted version of x.\n",
    "    \"\"\"\n",
    "    if dim is None:\n",
    "        # this weird code is necessary for toch.jit.script typing\n",
    "        dim = [0] * (x.dim())\n",
    "        for i in range(1, x.dim()):\n",
    "            dim[i] = i\n",
    "\n",
    "    # also necessary for torch.jit.script\n",
    "    shift = [0] * len(dim)\n",
    "    for i, dim_num in enumerate(dim):\n",
    "        shift[i] = x.shape[dim_num] // 2\n",
    "\n",
    "    return roll(x, shift, dim)\n",
    "\n",
    "\n",
    "def ifftshift(x: torch.Tensor, dim: Optional[List[int]] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.fft.ifftshift but applies to PyTorch Tensors\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        dim: Which dimension to ifftshift.\n",
    "    Returns:\n",
    "        ifftshifted version of x.\n",
    "    \"\"\"\n",
    "    if dim is None:\n",
    "        # this weird code is necessary for toch.jit.script typing\n",
    "        dim = [0] * (x.dim())\n",
    "        for i in range(1, x.dim()):\n",
    "            dim[i] = i\n",
    "\n",
    "    # also necessary for torch.jit.script\n",
    "    shift = [0] * len(dim)\n",
    "    for i, dim_num in enumerate(dim):\n",
    "        shift[i] = (x.shape[dim_num] + 1) // 2\n",
    "\n",
    "    return roll(x, shift, dim)\n",
    "\n",
    "tonpy = lambda x: torch.view_as_complex(x).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting parameters and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nmonte = 250\n",
    "noivar = .001\n",
    "\n",
    "model_layers   = 2\n",
    "nonlinearity   = 'tanh'\n",
    "latent_num     = 1\n",
    "epoch          = 100000\n",
    "rep            = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = sio.loadmat('data//dictionary.mat')['dictionary']\n",
    "fort2shfl  = sio.loadmat('data/for_t2shfl.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask      = fort2shfl['for_t2shfl'][0][0][0]\n",
    "kspace    = fort2shfl['for_t2shfl'][0][0][1]\n",
    "coils     = fort2shfl['for_t2shfl'][0][0][2]\n",
    "truth     = fort2shfl['for_t2shfl'][0][0][3]\n",
    "\n",
    "all_num_latent_linear = [2,3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_basis = []\n",
    "\n",
    "for num_latent_linear in all_num_latent_linear:\n",
    "    [U,S,V] = np.linalg.svd(dictionary,full_matrices=False)\n",
    "    basis   = U[:,:num_latent_linear]\n",
    "    \n",
    "    all_basis.append(basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting operators and preparing k-space without added noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[M,N,C,E] = kspace.shape\n",
    "\n",
    "coils_torch   = torch.stack((torch.tensor(np.real(coils),dtype=torch.float),\\\n",
    "                torch.tensor(np.imag(coils),dtype=torch.float)),dim=-1).to(device).reshape(M,N,C,1,2)\n",
    "coils_torch.requires_grad = False\n",
    "\n",
    "mask_torch    = torch.stack((torch.tensor(mask,dtype=torch.float),\\\n",
    "                             torch.tensor(mask,dtype=torch.float)),dim=-1).to(device)\n",
    "mask_torch.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfor_lin(x,I,B):\n",
    "    '''\n",
    "    Performs linear temporal forward in pytorch.\n",
    "    inputs:\n",
    "        x (M x N x 1 x B x 2)      - set of coefficients to go through the forward operator\n",
    "        I (E x B x 2)              - tempral basis\n",
    "    outputs:\n",
    "        out (M x N x 1 x T x 2)    - time series of images from coefficients\n",
    "    '''\n",
    "    x = x.reshape(M*N*1,B,2).permute(1,0,2)\n",
    "    return torch.stack((torch.matmul(I[...,0],x[...,0]),torch.matmul(I[...,0],x[...,1])),\\\n",
    "                  dim = -1).permute(1,0,2).reshape(M,N,1,E,2)\n",
    "\n",
    "def tadj_lin(x,I,B):\n",
    "    '''\n",
    "    Performs linear temporal adjoint in pytorch.\n",
    "    inputs:\n",
    "        x (M x N x 1 x E x 2)      - set of images to go through the adjoint operator\n",
    "        I (E x B x 2)              - tempral basis\n",
    "    outputs:\n",
    "        out (M x N x 1 x T x 2)    - coefficients generated from time series of images\n",
    "    '''\n",
    "    x = x.reshape(M*N*1,E,2).permute(1,0,2)\n",
    "    \n",
    "    return torch.stack((torch.matmul(I[...,0].transpose(1,0),x[...,0]),\\\n",
    "                 torch.matmul(I[...,1].transpose(1,0),x[...,1])),dim = -1).permute(1,0,2).reshape(M,N,1,B,2)\n",
    "\n",
    "def sfor(x,CC):\n",
    "    '''\n",
    "    Performs forward coil sensitivity multiplication\n",
    "    inputs:\n",
    "        x  (M x N x 1 x T x 2)    - time series of images\n",
    "        CC (M x N x C x 1 x 2)    - coil sensitivity functions\n",
    "    output\n",
    "        out (M x N x C x T x 2)   - output\n",
    "    '''\n",
    "    return torch.stack((x[..., 0] * CC[..., 0] - x[..., 1] * CC[..., 1],\\\n",
    "                       x[..., 0] * CC[..., 1] + x[..., 1] * CC[..., 0]),-1)\n",
    "\n",
    "def ffor(data):\n",
    "    '''\n",
    "    Performs a forward fourier transform\n",
    "    inputs:\n",
    "          x (M x N x C x T x 2)\n",
    "    outputs:\n",
    "        out (M x N x X x T x 2)\n",
    "             \n",
    "    '''\n",
    "    \n",
    "    return ifftshift(torch.fft(fftshift(data,dim = [0,1]).permute(2,3,0,1,4),signal_ndim = 2,normalized = True).permute(2,3,0,1,4),dim = [0,1])\n",
    "\n",
    "def R(data,mask):\n",
    "    '''\n",
    "    Apply undersampling mask to some input\n",
    "    inputs:\n",
    "        data  (M x N x C x T x 2)     - input to be masked\n",
    "        mask  (M x N x 1 x T x 1)     - mask to be applied\n",
    "    '''\n",
    "    \n",
    "    return data * mask\n",
    "\n",
    "\n",
    "def Dfor(model):\n",
    "    '''\n",
    "    Takes an input data through the decoder trained for compressing signal evolution\n",
    "    input\n",
    "        data (M*N x L x 2)   - input data\n",
    "        model              - neural network model\n",
    "    output\n",
    "        out (256 x 256 x 1 x T x 2)\n",
    "    '''\n",
    "    \n",
    "    out = model.decode(x)\n",
    "    return torch.stack((out * xr,out * xi),-1).reshape(M,N,1,E,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating and reconstructing k-space with different noice instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'data/model_layers_%d_nonlin_%s_latent_%d_epochs_%d_rep%d_sim.pt' % \\\n",
    "    (model_layers,nonlinearity,latent_num,epoch,rep)\n",
    "model = torch.load(model_path).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfl\n",
    "\n",
    "iter_deco   = 1000\n",
    "iter_bart   = 100\n",
    "\n",
    "#-preparations for bart reconstruction\n",
    "all_timeseries_bart    = np.zeros((M,N,E,nmonte,len(all_basis)),dtype = complex)\n",
    "all_timeseries_decoder = np.zeros((M,N,E,nmonte),dtype = complex)\n",
    "\n",
    "coils_bart  = coils.reshape(M,N,1,C,1)\n",
    "\n",
    "for nm in range(nmonte):\n",
    "    print('monte %d/%d' % (nm+1,nmonte))\n",
    "    cur_noise = np.random.normal(0,noivar,size = kspace.shape) + 1j * np.random.normal(0,noivar,size = kspace.shape)\n",
    "    kspace_noise = kspace + cur_noise\n",
    "    \n",
    "    #DECODER RECONSTRUCTIONS\n",
    "    print('  decoder recon')\n",
    "    kspace_torch   = torch.stack((torch.tensor(np.real(kspace_noise),dtype=torch.float),\\\n",
    "                torch.tensor(np.imag(kspace_noise),dtype=torch.float)),dim=-1).to(device)\n",
    "    kspace_torch.requires_grad = False\n",
    "\n",
    "    kspace_torch = R(kspace_torch,mask_torch)\n",
    "    \n",
    "    x  = torch.zeros(M*N,latent_num).to(device).detach()\n",
    "\n",
    "    xr = torch.ones(M*N,1).to(device).detach() \n",
    "    xi = torch.zeros(M*N,1).to(device).detach() \n",
    "\n",
    "    x.requires_grad  = True\n",
    "    xr.requires_grad = True\n",
    "    xi.requires_grad = True\n",
    "\n",
    "    criterion   = nn.MSELoss()\n",
    "    optimizer   = optim.Adam([x,xr,xi],lr = 1e0)\n",
    "    \n",
    "    for iter in range(iter_deco):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss   = criterion(kspace_torch,R(ffor(sfor(Dfor(model),coils_torch)),mask_torch))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "\n",
    "        if iter % 250 == 0:\n",
    "            print('    iteration %d / %d, current loss: %.12f' % (iter,iter_bart,running_loss))\n",
    "\n",
    "    timeseries_decoder = tonpy((Dfor(model).detach().squeeze().contiguous()))\n",
    "    all_timeseries_decoder[:,:,:,nm] = timeseries_decoder\n",
    "    \n",
    "    #BART RECONSTRUCTIONS\n",
    "    kspace_bart = (kspace_noise * mask).reshape(M,N,1,C,1,E)\n",
    "    \n",
    "    ctr_b = 0\n",
    "    for basis in all_basis:\n",
    "        B = basis.shape[1]\n",
    "        print('  basis %d/%d' % (ctr_b+1,len(all_basis)))\n",
    "        \n",
    "        basis_bart  = basis.reshape(1,1,1,1,1,E,B)\n",
    "        cfl.writecfl('data/basis_bart',basis_bart)\n",
    "        \n",
    "        #-no regularization bart string\n",
    "        bartstr = 'pics -B data/basis_bart -i %d' % (iter_bart)\n",
    "        \n",
    "        #-reconstruction\n",
    "        coeffs_bart     = np.squeeze(bart.bart(1,bartstr,kspace_bart,coils_bart))\n",
    "        timeseries_bart = (basis @ coeffs_bart.transpose(2,0,1).reshape(B,M*N)).reshape(E,M,N).transpose(1,2,0)\n",
    "        \n",
    "        all_timeseries_bart[:,:,:,nm,ctr_b] = timeseries_bart\n",
    "        \n",
    "        ctr_b += 1\n",
    "        \n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing statistics with respect to fully sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -multiplying by brain mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask = np.zeros((M,N))\n",
    "brain_mask[np.where(np.abs(truth[:,:,0,0])>0)] =1\n",
    "brain_mask = np.expand_dims(brain_mask,axis=2)\n",
    "\n",
    "all_timeseries_bart    = all_timeseries_bart * brain_mask.reshape(M,N,1,1,1)\n",
    "all_timeseries_decoder = all_timeseries_decoder * brain_mask.reshape(M,N,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -computing RMSE at each echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_decoder = np.zeros((E,nmonte))\n",
    "rmse_bart    = np.zeros((E,nmonte,len(all_basis)))\n",
    "\n",
    "for ee in range(E):\n",
    "    truth_comp = sig.nor(np.abs(truth[:,:,0,ee]))\n",
    "    for nm in range(nmonte):\n",
    "        rmse_decoder[ee,nm] = sig.rmse(truth_comp,sig.nor(np.abs(all_timeseries_decoder[:,:,ee,nm])))\n",
    "    \n",
    "        for bb in range(len(all_basis)):\n",
    "            rmse_bart[ee,nm,bb] = sig.rmse(truth_comp,sig.nor(np.abs(all_timeseries_bart[:,:,ee,nm,bb])))\n",
    "            \n",
    "#-plotting average rmse for each echo just to get an idea of what's going on\n",
    "leg = []\n",
    "plt.plot(np.mean(rmse_decoder,1))\n",
    "leg.append('dec')\n",
    "for bb in range(len(all_basis)):\n",
    "    leg.append('lin %d' % (bb+2))\n",
    "    plt.plot(np.mean(rmse_bart[:,:,bb],1))\n",
    "\n",
    "plt.legend(leg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -computing average error map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_decoder = np.zeros((M,N,E))\n",
    "error_bart    = np.zeros((M,N,E,len(all_basis)))\n",
    "\n",
    "variance_decoder = np.zeros((M,N,E))\n",
    "variance_bart    = np.zeros((M,N,E,len(all_basis)))\n",
    "\n",
    "for ee in range(E):\n",
    "    truth_comp = sig.nor(np.abs(truth[:,:,0,ee]))\n",
    "    \n",
    "    differences_decoder = np.zeros((M,N,nmonte))\n",
    "    for nm in range(nmonte):\n",
    "        differences_decoder[:,:,nm] = (truth_comp - sig.nor(np.abs(all_timeseries_decoder[:,:,ee,nm])))**2\n",
    "    \n",
    "    error_decoder[:,:,ee]    = np.sqrt(np.sum(differences_decoder,-1)) / np.sqrt(nmonte*(truth_comp**2))\n",
    "    variance_decoder[:,:,ee] = np.var(np.sqrt(differences_decoder),-1)\n",
    "    \n",
    "    for bb in range(len(all_basis)):\n",
    "        differences_bart = np.zeros((M,N,nmonte))\n",
    "        for nm in range(nmonte):\n",
    "            differences_bart[:,:,nm] = (truth_comp - sig.nor(np.abs(all_timeseries_bart[:,:,ee,nm,bb])))**2\n",
    "        \n",
    "        error_bart[:,:,ee,bb]    = np.sqrt(np.sum(differences_bart,-1)) / np.sqrt(nmonte*(truth_comp**2))\n",
    "        variance_bart[:,:,ee,bb] = np.var(np.sqrt(differences_bart),-1)\n",
    "\n",
    "    error_bart    = np.nan_to_num(error_bart)\n",
    "    error_decoder = np.nan_to_num(error_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick comparison of error maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ech = 20\n",
    "cl  = [0,.1]\n",
    "\n",
    "display = np.concatenate((np.expand_dims(error_decoder[:,:,ech],axis=0),\\\n",
    "                         error_bart[:,:,ech,:].transpose(2,0,1)),axis=0)\n",
    "\n",
    "sig.mosaic(display,1,3,clim=cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show reconstruction for a particular echo / noise instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ech = 10;\n",
    "nm  = 0;\n",
    "cl  = [0,1]\n",
    "\n",
    "display = np.concatenate((sig.nor(np.expand_dims(all_timeseries_decoder[:,:,ech,nm],axis=0)),\\\n",
    "                         sig.nor(all_timeseries_bart[:,:,ech,nm,:]).transpose(2,0,1)),axis=0)\n",
    "\n",
    "sig.mosaic(display,1,3,clim=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
